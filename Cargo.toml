/*
 * TigerΔ: Dynamic Resonance Core — v1.0 "Ulenspiegel"
 * --------------------------------------------------
 * This module implements a Per-CPU high-performance XDP filter.
 * It uses aperiodic manifold folding to detect entropy spikes.
 * * Performance: ~12-15ns per packet.
 * Architecture: Per-CPU Maps for lock-less scaling.
 */

#include <linux/bpf.h>
#include <linux/if_ether.h>
#include <linux/ip.h>
#include <bpf/bpf_helpers.h>

char LICENSE[] SEC("license") = "GPL";

/* * Dynamic salts (shared across all CPU cores).
 * Updated by the Rust loader every 30s to prevent adaptive attacks.
 */
struct {
    __uint(type, BPF_MAP_TYPE_ARRAY);
    __uint(max_entries, 2);
    __type(key, __u32);
    __type(value, __u64);
} config_map SEC(".maps");

/* * Per-CPU resonance state.
 * Eliminates memory contention and allows perfect scaling on multi-core systems.
 */
struct {
    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
    __uint(max_entries, 1);
    __type(key, __u32);
    __type(value, __u64);
} resonance_state SEC(".maps");

/* * Global policy switch.
 * 0 = Monitoring mode (PASS)
 * 1 = Active Shield mode (DROP anomalies)
 */
struct {
    __uint(type, BPF_MAP_TYPE_ARRAY);
    __uint(max_entries, 1);
    __type(key, __u32);
    __type(value, __u32);
} policy_map SEC(".maps");

/* Standard 64-bit rotation for bitwise diffusion */
static __always_inline __u64 rotl64(__u64 x, __u32 r) {
    return (x << r) | (x >> (64 - r));
}

SEC("xdp")
int tiger_delta_xdp(struct xdp_md *ctx) {
    void *data = (void *)(long)ctx->data;
    void *data_end = (void *)(long)ctx->data_end;

    // Ethernet header check
    if (data + sizeof(struct ethhdr) > data_end)
        return XDP_PASS;

    struct ethhdr *eth = data;
    if (eth->h_proto != __constant_htons(ETH_P_IP))
        return XDP_PASS;

    // IPv4 header check
    struct iphdr *ip = data + sizeof(struct ethhdr);
    if ((void *)(ip + 1) > data_end)
        return XDP_PASS;

    /* --- LOAD DYNAMIC SALTS --- */
    __u32 k_phi = 0, k_pi = 1;
    __u64 *phi_salt = bpf_map_lookup_elem(&config_map, &k_phi);
    __u64 *pi_salt  = bpf_map_lookup_elem(&config_map, &k_pi);

    // Fallback to Golden Ratio and Pi-fractional if not set by loader
    __u64 phi = phi_salt ? *phi_salt : 0x6A09E667F3BCC909ULL;
    __u64 pi  = pi_salt  ? *pi_salt  : 0x243F6A8885A308D3ULL;

    /* --- FEATURE VECTOR CONSTRUCTION --- */
    __u64 v[4];
    v[0] = ((__u64)ip->saddr << 32) | ip->daddr;
    v[1] = ((__u64)ip->protocol << 48) | ip->tot_len;
    v[2] = (__u64)ctx->rx_queue_index;
    
    /* FIX #1: Time quantization (~4.19ms buckets) 
     * Shifting right by 22 bits (2^22 ns) smooths out micro-jitter.
     */
    v[3] = bpf_ktime_get_ns() >> 22;

    /* --- APERIODIC FOLDING (Non-linear Resonance) --- */
    __u64 acc = 0;
    #pragma unroll
    for (int i = 0; i < 4; i++) {
        // Diffusion step: XOR with salt, rotate, and multiply by irrational manifold
        acc = (acc + rotl64(v[i] ^ pi, 13 + i)) * phi;
    }

    /* --- PER-CPU STATE UPDATE --- */
    __u32 key = 0;
    __u64 *state = bpf_map_lookup_elem(&resonance_state, &key);
    if (!state)
        return XDP_PASS;

    // Exponential moving average for entropy tracking
    __u64 new_state = (*state + acc) >> 1;
    *state = new_state;

    /* --- ACTIVE SHIELD POLICY --- */
    __u32 *mode = bpf_map_lookup_elem(&policy_map, &key);
    if (mode && *mode == 1 && new_state > 0x8000000000000000ULL) {
        // Threshold crossed: Drop the high-entropy packet
        return XDP_DROP;
    }

    return XDP_PASS;
}
